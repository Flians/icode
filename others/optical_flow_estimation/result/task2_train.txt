Parsing Arguments
  [0.023s] batch_size: 32
  [0.023s] crop_size: [192, 256]
  [0.023s] fp16: False
  [0.023s] fp16_scale: 1024.0
  [0.023s] gradient_clip: None
  [0.023s] inference: False
  [0.023s] inference_batch_size: 1
  [0.023s] inference_dataset: MpiSintelClean
  [0.023s] inference_dataset_replicates: 1
  [0.023s] inference_dataset_root: data/validation
  [0.023s] inference_n_batches: -1
  [0.023s] inference_size: [-1, -1]
  [0.023s] inference_visualize: False
  [0.023s] log_frequency: 1
  [0.023s] loss: EPELoss
  [0.023s] loss_div_flow: 0.05
  [0.023s] model: FlowNetE
  [0.023s] model_div_flow: 20
  [0.023s] name: run
  [0.023s] no_cuda: False
  [0.023s] number_gpus: 1
  [0.023s] number_workers: 8
  [0.023s] optimizer: Adam
  [0.023s] optimizer_amsgrad: False
  [0.023s] optimizer_betas: (0.9, 0.999)
  [0.023s] optimizer_eps: 1e-08
  [0.023s] optimizer_lr: 0.0001
  [0.023s] optimizer_weight_decay: 0
  [0.023s] render_validation: False
  [0.023s] replicates: 1
  [0.023s] resume: 
  [0.023s] rgb_max: 255.0
  [0.023s] save: ./work
  [0.023s] save_flow: False
  [0.023s] schedule_lr_fraction: 10
  [0.023s] schedule_lr_frequency: 0
  [0.023s] seed: 1
  [0.023s] skip_training: False
  [0.023s] skip_validation: False
  [0.023s] start_epoch: 1
  [0.023s] total_epochs: 51
  [0.023s] train_n_batches: -1
  [0.023s] training_dataset: MpiSintelClean
  [0.023s] training_dataset_replicates: 1
  [0.023s] training_dataset_root: data/training
  [0.023s] validation_dataset: MpiSintelClean
  [0.023s] validation_dataset_replicates: 1
  [0.023s] validation_dataset_root: data/validation
  [0.023s] validation_frequency: 5
  [0.023s] validation_n_batches: -1
  [0.031s] Operation finished

Source Code
Initializing Datasets
  [0.020s] Training Dataset: MpiSintelClean
  [0.028s] Training Input: [3, 2, 192, 256]
  [0.036s] Training Targets: [2, 192, 256]
  [0.041s] Validation Dataset: MpiSintelClean
  [0.051s] Validation Input: [3, 2, 192, 512]
  [0.061s] Validation Targets: [2, 192, 512]
  [0.065s] Inference Dataset: MpiSintelClean
  [0.075s] Inference Input: [3, 2, 192, 512]
  [0.084s] Inference Targets: [2, 192, 512]
  [0.084s] Operation finished

Building FlowNetE model
div_flow 20
### Print Model Flops ###
conv: 2172.32M
linear: 0.00M
bn: 0.00M
relu: 1.57M
pool: 0.00M
  + Number of FLOPs: 2173.90M
conv 4.59M
linear: 0.00M
total_params 4.59M
### end of Flops Calc ###
  [0.060s] Effective Batch Size: 32
  [0.060s] Number of parameters: 4592450
  [0.060s] Initializing CUDA
  [1.506s] Parallelizing
  [1.507s] Random initialization
  [1.507s] Initializing save directory: ./work
  [1.512s] Operation finished

Initializing Adam Optimizer
  [0.000s] amsgrad = False (<class 'bool'>)
  [0.000s] weight_decay = 0 (<class 'int'>)
  [0.000s] eps = 1e-08 (<class 'float'>)
  [0.000s] betas = (0.9, 0.999) (<class 'tuple'>)
  [0.000s] lr = 0.0001 (<class 'float'>)
  [0.000s] Operation finished

Epoch 1/52 : loss: 0.3231
Eval on validation set
Eval-iters: 0/147
Eval-iters: 73/147
Eval-iters: 146/147
Obtain better valid loss : 100000000.0000 |--> 6.9944
Epoch 2/52 : loss: 0.3171
Epoch 3/52 : loss: 0.3089
Epoch 4/52 : loss: 0.3088
Epoch 5/52 : loss: 0.2897
Epoch 6/52 : loss: 0.2973
Eval on validation set
Eval-iters: 0/147
Eval-iters: 73/147
Eval-iters: 146/147
Obtain better valid loss : 6.9944 |--> 6.7185
Epoch 7/52 : loss: 0.2789
Epoch 8/52 : loss: 0.2736
Epoch 9/52 : loss: 0.2637
Epoch 10/52 : loss: 0.2674
Epoch 11/52 : loss: 0.2586
Eval on validation set
Eval-iters: 0/147
Eval-iters: 73/147
Eval-iters: 146/147
Obtain better valid loss : 6.7185 |--> 5.9772
Epoch 12/52 : loss: 0.2606
Epoch 13/52 : loss: 0.2515
Epoch 14/52 : loss: 0.2424
Epoch 15/52 : loss: 0.2487
Epoch 16/52 : loss: 0.2520
Eval on validation set
Eval-iters: 0/147
Eval-iters: 73/147
Eval-iters: 146/147
best valid loss unchange: 5.9772 
Epoch 17/52 : loss: 0.2365
Epoch 18/52 : loss: 0.2461
Epoch 19/52 : loss: 0.2437
Epoch 20/52 : loss: 0.2419
Epoch 21/52 : loss: 0.2436
Eval on validation set
Eval-iters: 0/147
Eval-iters: 73/147
Eval-iters: 146/147
best valid loss unchange: 5.9772 
Epoch 22/52 : loss: 0.2387
Epoch 23/52 : loss: 0.2340
Epoch 24/52 : loss: 0.2371
Epoch 25/52 : loss: 0.2371
Epoch 26/52 : loss: 0.2315
Eval on validation set
Eval-iters: 0/147
Eval-iters: 73/147
Eval-iters: 146/147
best valid loss unchange: 5.9772 
Epoch 27/52 : loss: 0.2210
Epoch 28/52 : loss: 0.2316
Epoch 29/52 : loss: 0.2225
Epoch 30/52 : loss: 0.2202
Epoch 31/52 : loss: 0.2229
Eval on validation set
Eval-iters: 0/147
Eval-iters: 73/147
Eval-iters: 146/147
Obtain better valid loss : 5.9772 |--> 5.9442
Epoch 32/52 : loss: 0.2249
Epoch 33/52 : loss: 0.2204
Epoch 34/52 : loss: 0.2195
Epoch 35/52 : loss: 0.2249
Epoch 36/52 : loss: 0.2168
Eval on validation set
Eval-iters: 0/147
Eval-iters: 73/147
Eval-iters: 146/147
best valid loss unchange: 5.9442 
Epoch 37/52 : loss: 0.2224
Epoch 38/52 : loss: 0.2163
Epoch 39/52 : loss: 0.2162
Epoch 40/52 : loss: 0.2121
Epoch 41/52 : loss: 0.2084
Eval on validation set
Eval-iters: 0/147
Eval-iters: 73/147
Eval-iters: 146/147
best valid loss unchange: 5.9442 
Epoch 42/52 : loss: 0.2050
Epoch 43/52 : loss: 0.2167
Epoch 44/52 : loss: 0.2185
Epoch 45/52 : loss: 0.2081
Epoch 46/52 : loss: 0.2033
Eval on validation set
Eval-iters: 0/147
Eval-iters: 73/147
Eval-iters: 146/147
best valid loss unchange: 5.9442 
Epoch 47/52 : loss: 0.2173
Epoch 48/52 : loss: 0.2032
Epoch 49/52 : loss: 0.2071
Epoch 50/52 : loss: 0.2061
Eval on validation set
Eval-iters: 0/147
Eval-iters: 73/147
Eval-iters: 146/147
best valid loss unchange: 5.9442 
Epoch 51/52 : loss: 0.2074
Eval on validation set
Eval-iters: 0/147
Eval-iters: 73/147
Eval-iters: 146/147
best valid loss unchange: 5.9442 
